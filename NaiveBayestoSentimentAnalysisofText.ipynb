{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1a6jCdcjnfVHHBbyRibOG4ycDKKEvN6Ed",
      "authorship_tag": "ABX9TyOpYKNIloysEAXIVGv0OzvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahminmahili/sentiment-analysis-of-text-using-naive-bayes/blob/main/NaiveBayestoSentimentAnalysisofText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXrM91gG6H7x",
        "outputId": "4a3f821b-4d37-48f7-ff6a-38317f678d96"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jophv7Fp_yMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 1: Implementing Naive Bayes Algorithm from Scratch"
      ],
      "metadata": {
        "id": "2shGVl1y_olo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define folder paths\n",
        "neg_folder_path = '/content/drive/MyDrive/txt_sentoken/neg'\n",
        "pos_folder_path = '/content/drive/MyDrive/txt_sentoken/pos'\n",
        "\n",
        "def load_data(folder_path, label):\n",
        "    data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        with open(os.path.join(folder_path, filename), 'r', encoding='latin1') as file:\n",
        "            text = file.read()\n",
        "            data.append((text.lower(), label))\n",
        "    return data\n",
        "\n",
        "# Load positive and negative data\n",
        "pos_data = load_data(pos_folder_path, 'positive')\n",
        "neg_data = load_data(neg_folder_path, 'negative')\n",
        "\n",
        "# Combine datasets\n",
        "full_data = pos_data + neg_data\n"
      ],
      "metadata": {
        "id": "kf6rzsh28JeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipbcLXIV8jIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "train_data, test_data = train_test_split(full_data, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "2hN-ao9x8jpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqcRti358vKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.class_probabilities = defaultdict(float)\n",
        "        self.word_given_class_probabilities = defaultdict(lambda: defaultdict(float))\n",
        "        self.vocabulary = set()\n",
        "\n",
        "    def train(self, data):\n",
        "        # Count class occurrences and word occurrences\n",
        "        class_counts = defaultdict(int)\n",
        "        word_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        for text, label in data:\n",
        "            class_counts[label] += 1\n",
        "            for word in text.split():\n",
        "                word_counts[label][word] += 1\n",
        "                self.vocabulary.add(word)\n",
        "\n",
        "        # Calculate probabilities\n",
        "        total_documents = len(data)\n",
        "        for label, count in class_counts.items():\n",
        "            self.class_probabilities[label] = count / total_documents\n",
        "            for word in self.vocabulary:\n",
        "                self.word_given_class_probabilities[label][word] = (\n",
        "                    (word_counts[label][word] + 1) /\n",
        "                    (sum(word_counts[label].values()) + len(self.vocabulary))\n",
        "                )\n",
        "\n",
        "    def predict(self, text):\n",
        "        # Calculate class scores\n",
        "        scores = {label: np.log(self.class_probabilities[label]) for label in self.class_probabilities}\n",
        "\n",
        "        for word in text.split():\n",
        "            if word in self.vocabulary:\n",
        "                for label in scores:\n",
        "                    scores[label] += np.log(self.word_given_class_probabilities[label][word])\n",
        "\n",
        "        # Return the label with the highest score\n",
        "        return max(scores, key=scores.get)\n"
      ],
      "metadata": {
        "id": "fPOtvUht8ve-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l0aTrIqL8yi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the model\n",
        "nb_model = NaiveBayes()\n",
        "nb_model.train(train_data)\n"
      ],
      "metadata": {
        "id": "TBxsUAG48yzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yuqq0QL9ESl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on test data\n",
        "test_texts, test_labels = zip(*test_data)\n",
        "predictions = [nb_model.predict(text) for text in test_texts]\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(f'Accuracy From Scratch: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeuDBrdA9EkO",
        "outputId": "89be298a-e125-4bcc-a70a-ce64abee09ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy From Scratch: 79.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OlJS_XJY9Ot4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 2: Implementing Naive Bayes Algorithm using Python Library"
      ],
      "metadata": {
        "id": "6ysrz49p9POA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Function to load data from a folder\n",
        "def load_data(folder_path, label):\n",
        "    data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "            data.append((text, label))\n",
        "    return data\n",
        "\n",
        "# Paths to the \"neg\" and \"pos\" folders\n",
        "neg_folder_path = '/content/drive/MyDrive/txt_sentoken/neg'\n",
        "pos_folder_path = '/content/drive/MyDrive/txt_sentoken/pos'\n",
        "\n",
        "# Load positive and negative data\n",
        "pos_data = load_data(pos_folder_path, 'positive')\n",
        "neg_data = load_data(neg_folder_path, 'negative')\n",
        "\n",
        "# Combine datasets\n",
        "full_data = pos_data + neg_data\n",
        "\n",
        "# Split data\n",
        "train_data, test_data = train_test_split(full_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract texts and labels\n",
        "train_texts, train_labels = zip(*train_data)\n",
        "test_texts, test_labels = zip(*test_data)\n",
        "\n",
        "# Create a pipeline with CountVectorizer and Multinomial Naive Bayes\n",
        "nb_pipeline = make_pipeline(CountVectorizer(), MultinomialNB())\n",
        "\n",
        "# Train the model\n",
        "nb_pipeline.fit(train_texts, train_labels)\n",
        "\n",
        "# Make predictions\n",
        "nb_predictions = nb_pipeline.predict(test_texts)\n",
        "\n",
        "# Evaluate accuracy\n",
        "nb_accuracy = accuracy_score(test_labels, nb_predictions)\n",
        "print(f'Accuracy using Python library: {nb_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK0ydN1B9Q8v",
        "outputId": "82b24a16-8c15-4723-da12-4ba9889b68b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using Python library: 78.86%\n"
          ]
        }
      ]
    }
  ]
}